---
title: "Transformer-based EEG Decoding: A Survey"
collection: publications
category: manuscripts
permalink: /publication/2009-10-01-paper-title-number-1
excerpt: 'Electroencephalography (EEG) is one of the most common signals used to capture the electrical activity of the brain, and the decoding of EEG, to acquire the user intents, has been at the forefront of brain-computer/machine interfaces (BCIs/BMIs) research. Compared to traditional EEG analysis methods with machine learning, the advent deep learning approach has gradually revolutionized the field by providing an end-to-end long-cascaded architecture, which can learn more discriminative features automatically. Among these, Transformer is renowned for its strong handling capability of sequential data by the attention mechanism, and the application of Transformers in various EEG processing tasks is increasingly prevalent. This article delves into a relevant survey, summarizing the latest application of transformer models in EEG decoding since it appeared. The evolution of the model architecture is followed to sort and organize the related advances, in which we first elucidate the fundamental model and principle of the Transformer that benefits EEG decoding. Then, the common integration of the basic transformer with other deep learning techniques (convolutional/ recurrent/graph/spiking neural networks, generative adversarial networks, etc.) is overviewed in detail. The research advances from two other perspectives of applying the vision and modified transformers have also been introduced. We further present the research status of the recent state-of-the-art large models, where we define and characterize for the first time the large brain-signal model. The current challenges and future development prospects in this rapidly evolving field are also discussed. This paper aims to help readers gain a clear understanding of the current state of Transformer model applications in EEG decoding and to provide valuable insights and guidance for future research endeavors.'
date: 2024-07-25
venue: 'Journal 1'
slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'http://academicpages.github.io/files/paper1.pdf'
citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---

The contents above will be part of a list of publications, if the user clicks the link for the publication than the contents of section will be rendered as a full page, allowing you to provide more information about the paper for the reader. When publications are displayed as a single page, the contents of the above "citation" field will automatically be included below this section in a smaller font.
